# Titanic - Machine Learning from Disaster

## ğŸš¢ Project Overview
This project is a solution to the famous **Titanic - Machine Learning from Disaster** Kaggle competition. The goal is to predict the survival of passengers based on various features such as age, gender, class, and ticket fare.

I explored multiple machine learning models to achieve the best accuracy, including Logistic Regression, KNN, SVM, Decision Tree, Random Forest, AdaBoost, Gradient Boosting, XGBoost, and an Artificial Neural Network (ANN).

---

## ğŸ“Š Model Performance
Below are the accuracy scores for different models:

| Model | Training Accuracy | Testing Accuracy | Cross-Validation Score |
|--------|------------------|------------------|-----------------------|
| **Logistic Regression** | 83.55% | 74.36% | 82.42% |
| **KNN** | 83.06% | 73.72% | 82.42% |
| **SVM** | 82.58% | 74.36% | 82.58% |
| **Decision Tree** | 65.97% | 65.38% | 65.16% |
| **Random Forest** | 93.55% | 73.72% | 79.03% |
| **AdaBoostClassifier** | 83.06% | 75.00% | 83.06% |
| **GradientBoostingClassifier** | 83.06% | 75.00% | 83.06% |
| **XGBClassifier** | 86.13% | 75.00% | 83.23% |
| **Artificial Neural Network (ANN)** | **83%** | **80.14%** | **81.77%** |

---

## ğŸ† Kaggle Competition Results
- **Final ANN Model Score**: **0.80143**
- **Kaggle Rank**: **750 out of 1,363,384** entrants ğŸ‰
- **Top 5% of all participants!** ğŸŒŸ
- **Total Participants**: 16,170
- **Total Teams**: 16,104
- **Total Submissions**: 60,915

---

## ğŸ” Key Insights
âœ… **Feature Engineering**: Handling missing values, encoding categorical features, and feature scaling improved model performance.

âœ… **Hyperparameter Tuning**: Optimized model parameters for better accuracy.

âœ… **Ensemble Learning**: Boosting models (Gradient Boosting, AdaBoost, XGBoost) performed well compared to individual classifiers.

âœ… **Neural Network Power**: ANN achieved the best leaderboard score, proving its effectiveness in complex classification tasks.

---

## ğŸ› ï¸ Tech Stack
- **Python** ğŸ
- **Scikit-Learn** for Machine Learning models
- **TensorFlow/Keras** for ANN implementation
- **Pandas & NumPy** for data preprocessing
- **Matplotlib & Seaborn** for data visualization

---


## ğŸ“Œ Conclusion
This project demonstrates the power of machine learning and deep learning in classification problems. By leveraging ensemble methods and ANN, I achieved **top 5% ranking** in the Kaggle competition. ğŸš€

Feel free to explore the code and suggest improvements! ğŸ’¡


