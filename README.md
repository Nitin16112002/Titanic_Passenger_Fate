# Titanic - Machine Learning from Disaster

## 🚢 Project Overview
This project is a solution to the famous **Titanic - Machine Learning from Disaster** Kaggle competition. The goal is to predict the survival of passengers based on various features such as age, gender, class, and ticket fare.

I explored multiple machine learning models to achieve the best accuracy, including Logistic Regression, KNN, SVM, Decision Tree, Random Forest, AdaBoost, Gradient Boosting, XGBoost, and an Artificial Neural Network (ANN).

---

## 📊 Model Performance
Below are the accuracy scores for different models:

| Model | Training Accuracy | Testing Accuracy | Cross-Validation Score |
|--------|------------------|------------------|-----------------------|
| **Logistic Regression** | 83.55% | 74.36% | 82.42% |
| **KNN** | 83.06% | 73.72% | 82.42% |
| **SVM** | 82.58% | 74.36% | 82.58% |
| **Decision Tree** | 65.97% | 65.38% | 65.16% |
| **Random Forest** | 93.55% | 73.72% | 79.03% |
| **AdaBoostClassifier** | 83.06% | 75.00% | 83.06% |
| **GradientBoostingClassifier** | 83.06% | 75.00% | 83.06% |
| **XGBClassifier** | 86.13% | 75.00% | 83.23% |
| **Artificial Neural Network (ANN)** | **83%** | **80.14%** | **81.77%** |

---

## 🏆 Kaggle Competition Results
- **Final ANN Model Score**: **0.80143**
- **Kaggle Rank**: **750 out of 1,363,384** entrants 🎉
- **Top 5% of all participants!** 🌟
- **Total Participants**: 16,170
- **Total Teams**: 16,104
- **Total Submissions**: 60,915

---

## 🔍 Key Insights
✅ **Feature Engineering**: Handling missing values, encoding categorical features, and feature scaling improved model performance.

✅ **Hyperparameter Tuning**: Optimized model parameters for better accuracy.

✅ **Ensemble Learning**: Boosting models (Gradient Boosting, AdaBoost, XGBoost) performed well compared to individual classifiers.

✅ **Neural Network Power**: ANN achieved the best leaderboard score, proving its effectiveness in complex classification tasks.

---

## 🛠️ Tech Stack
- **Python** 🐍
- **Scikit-Learn** for Machine Learning models
- **TensorFlow/Keras** for ANN implementation
- **Pandas & NumPy** for data preprocessing
- **Matplotlib & Seaborn** for data visualization

---


## 📌 Conclusion
This project demonstrates the power of machine learning and deep learning in classification problems. By leveraging ensemble methods and ANN, I achieved **top 5% ranking** in the Kaggle competition. 🚀

Feel free to explore the code and suggest improvements! 💡


